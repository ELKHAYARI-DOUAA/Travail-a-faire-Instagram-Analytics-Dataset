COMPTE RENDU Dâ€™ANALYSE DES DONNÃ‰ES
Dataset : Instagram Analytics

RÃ©alisÃ© par : Douaa El Khayari â€“ CAC2 â€“ ApogÃ©e : 24010315

1. Introduction

Dans un contexte oÃ¹ Instagram est devenu un outil central de communication, la comprÃ©hension des performances des publications est essentielle. Les entreprises, influenceurs et crÃ©ateurs de contenu doivent analyser leurs statistiques pour optimiser leur visibilitÃ© et amÃ©liorer lâ€™engagement de leur audience.

Cette Ã©tude utilise un dataset Instagram comportant 29 999 publications et 15 variables, permettant une analyse complÃ¨te de lâ€™interaction des utilisateurs.

2. ProblÃ©matique

La question centrale est :

Quels sont les facteurs principaux qui influencent lâ€™engagement sur Instagram, et dans quelle mesure peut-on prÃ©dire ce niveau dâ€™engagement ?

Pour y rÃ©pondre, lâ€™analyse sâ€™est dÃ©roulÃ©e en plusieurs phases :
chargement des donnÃ©es, preprocessing, feature engineering, exploration statistique, visualisation, modÃ©lisation et Ã©valuation.

3. Analyse dÃ©taillÃ©e cellule par cellule
ğŸ”µ Cellule 0 â€” Chargement du dataset et aperÃ§u
Code :
import pandas as pd

file_path = "/content/Instagram_Analytics.csv"
df = pd.read_csv(file_path)

print("Shape:", df.shape)
df.head()

Explication du code

pd.read_csv() charge le dataset depuis un fichier CSV.

df.shape permet de connaÃ®tre le nombre de lignes et de colonnes.

df.head() affiche les cinq premiÃ¨res lignes pour vÃ©rifier le format et les valeurs.

Sortie :
Shape: (29999, 15)

InterprÃ©tation

Nous avons un dataset trÃ¨s large (29 999 lignes) contenant 15 colonnes.
Cela assure une bonne diversitÃ© statistique et permet une modÃ©lisation de qualitÃ©.

ğŸ”µ Cellule 1 â€” Inspection des types + prÃ©paration date
Code :
df.info()

df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')

Explication

df.info() liste les types de donnÃ©es : int, float, object.

pd.to_datetime() convertit la colonne timestamp en un format date utilisable.

Sortie :

Affichage du nombre de colonnes, de leur type, et mÃ©moire utilisÃ©e.

InterprÃ©tation

Beaucoup de colonnes sont numÃ©riques â†’ bon pour lâ€™analyse statistique.

Certaines colonnes object devront Ãªtre transformÃ©es.

Conversion du timestamp est indispensable pour lâ€™analyse temporelle.

ğŸ”µ Cellule 2 â€” Calcul de lâ€™engagement
Code :
df['likes'] = df['likes'].fillna(0)
df['comments'] = df['comments'].fillna(0)

df['engagement'] = df['likes'] + df['comments']
df['engagement_rate'] = df['engagement'] / df['followers'] * 100

df[['engagement', 'engagement_rate']].head()

Explication

Remplacement des valeurs manquantes par 0 pour Ã©viter les erreurs de calcul.

Calcul de lâ€™engagement : somme des interactions directes.

Calcul de lâ€™engagement_rate (%) : mesure clÃ© sur Instagram.

InterprÃ©tation

Lâ€™engagement est proportionnel au nombre dâ€™abonnÃ©s.
Un taux important signifie que la publication attire rÃ©ellement lâ€™attention du public.

ğŸ”µ Cellule 3 â€” Feature Engineering (Nouvelles variables)
Code :
df['day'] = df['timestamp'].dt.day_name()
df['is_weekend'] = df['day'].isin(['Saturday', 'Sunday'])

df['caption_length'] = df['caption'].astype(str).apply(len)
df['hashtags_count'] = df['hashtags'].astype(str).apply(lambda x: len(x.split()))

Explication

On crÃ©e des nouvelles variables utiles :

jour de la semaine

weekend ou non

longueur de la lÃ©gende

nombre de hashtags

Sortie : affichage dâ€™un tableau avec ces colonnes.
InterprÃ©tation

Ces variables permettent de tester des hypothÃ¨ses comme :

Les posts du weekend performent-ils mieux ?

Les hashtags augmentent-ils lâ€™engagement ?

Une lÃ©gende longue attire-t-elle plus dâ€™attention ?

Ces features enrichissent grandement lâ€™analyse et les modÃ¨les ML.

ğŸ”µ Cellule 4 â€” Statistiques descriptives
Code :
df.describe()

Explication

Affiche des statistiques :
moyenne, mÃ©diane, minimum, maximum, quartilesâ€¦

InterprÃ©tation

Forte variance dans les likes â†’ certaines publications sont virales.

Ã‰carts extrÃªmes dans le reach â†’ certaines publications ont explosÃ© en visibilitÃ©.

Les commentaires sont plus faibles mais corrÃ©lÃ©s aux likes.

ğŸ”µ Cellule 5 â€” Visualisations (histogrammes)

Graphiques produits :

distribution des likes

distribution des followers

distribution des engagement_rates

InterprÃ©tation

Les likes sont asymÃ©triques â†’ beaucoup de posts faibles, quelques pics extraordinaires.

Les followers sont trÃ¨s concentrÃ©s â†’ peu dâ€™outliers.

Lâ€™engagement rate varie beaucoup, indiquant un public irrÃ©gulier.

ğŸ”µ Cellule 6 â€” Matrice de corrÃ©lation
Code :
plt.figure(figsize=(8,6))
sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("CorrÃ©lations")
plt.show()

Explication

Calcul des corrÃ©lations entre les variables numÃ©riques.

La heatmap aide Ã  repÃ©rer les relations fortes.

InterprÃ©tation

likes â†” engagement : corrÃ©lation trÃ¨s forte (logique).

followers â†” reach : une base solide augmente la portÃ©e.

hashtags â†” engagement_rate : faible corrÃ©lation â†’ les hashtags nâ€™aident pas toujours.

ğŸ”µ Cellule 7 â€” SÃ©lection des variables pour le modÃ¨le
Code :
feature_cols = ['caption_length','hashtags_count','likes','comments','is_weekend']
X = df[feature_cols]
y = df['engagement_rate']

Explication

On choisit les variables qui serviront au modÃ¨le prÃ©dictif.
La variable cible (target) est engagement_rate.

InterprÃ©tation

Les features combinent texte, comportement utilisateur, et interactions.

ğŸ”µ Cellule 8 â€” Train-test split
Code :
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

Explication

SÃ©paration du dataset : 80% entraÃ®nement, 20% test.

Important pour Ã©viter lâ€™overfitting.

InterprÃ©tation

Le modÃ¨le sera Ã©valuÃ© sur des donnÃ©es jamais vues, garantissant une performance fiable.

ğŸ”µ Cellule 9 â€” ModÃ¨le Ridge et mÃ©triques
Code :
model = Ridge()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

rmse = mean_squared_error(y_test, y_pred, squared=False)
r2 = r2_score(y_test, y_pred)

print("RMSE:", rmse)
print("RÂ²:", r2)

Sortie :
RMSE: 49.72
RÂ²: -0.0006

InterprÃ©tation

RMSE Ã©levÃ© (â‰ˆ 50) â†’ le modÃ¨le ne parvient pas Ã  prÃ©dire prÃ©cisÃ©ment le taux dâ€™engagement.

RÂ² nÃ©gatif â†’ le modÃ¨le fait pire quâ€™une prÃ©diction constante.

Conclusion locale

Le modÃ¨le Ridge nâ€™est pas adaptÃ©.
Les variables choisies ne suffisent pas Ã  expliquer lâ€™engagement.
Il faudra tester :
âœ” Random Forest
âœ” Gradient Boosting
âœ” XGBoost
âœ” non-linÃ©aritÃ©s et interactions

4. Conclusion gÃ©nÃ©rale

Cette Ã©tude montre que :

Le dataset est riche et permet une analyse dÃ©taillÃ©e.

Lâ€™engagement dÃ©pend fortement des likes, du reach et des interactions globales.

Les variables textuelles doivent Ãªtre mieux exploitÃ©es (NLP).

Les modÃ¨les linÃ©aires comme Ridge ne captent pas la complexitÃ© du phÃ©nomÃ¨ne.

Une approche non linÃ©aire ou deep learning serait plus performante.
